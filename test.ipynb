{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z)) \n",
    "    return A\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exponents = np.exp(x)\n",
    "    return exponents / np.sum(exponents)\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    return A\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def derivative_relu(Z):\n",
    "    return np.array(Z > 0, dtype = 'float')\n",
    "\n",
    "def derivative_tanh(x):\n",
    "    return (1 - np.power(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = pd.read_csv('Task_1/b/w-100-40-4.csv', header=None)\n",
    "# initial_weights = pd.read_csv('Task_1/a/w.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_biases  = pd.read_csv('Task_1/b/b-100-40-4.csv', header=None)\n",
    "# initial_biases = pd.read_csv('Task_1/a/b.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = initial_weights.iloc[0:14, 1:].to_numpy().astype(np.float32).T\n",
    "w2 = initial_weights.iloc[14:114, 1:41].to_numpy().astype(np.float32).T\n",
    "w3 = initial_weights.iloc[114:, 1:5].to_numpy().astype(np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 14), (40, 100), (4, 40))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape, w2.shape, w3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load initial Biases and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = initial_biases.iloc[0, 1:].to_numpy().astype(np.float32).T\n",
    "b2 = initial_biases.iloc[1, 1:41].to_numpy().astype(np.float32).T\n",
    "b3 = initial_biases.iloc[2, 1:5].to_numpy().astype(np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape b1s\n",
    "b1 = b1.reshape(-1,1)\n",
    "b2 = b2.reshape(-1,1)\n",
    "b3 = b3.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            \n",
    "\n",
    "    parameters['W' + str(1)] = w1\n",
    "    parameters['b' + str(1)] = b1\n",
    "\n",
    "    parameters['W' + str(2)] = w2\n",
    "    parameters['b' + str(2)] = b2\n",
    "\n",
    "    parameters['W' + str(3)] = w3\n",
    "    parameters['b' + str(3)] = b3   \n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of W1: (100, 14)\n",
      "Shape of B1: (100, 1) \n",
      "\n",
      "Shape of W2: (40, 100)\n",
      "Shape of B2: (40, 1) \n",
      "\n",
      "Shape of W3: (4, 40)\n",
      "Shape of B3: (4, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layer_dims = [14, 100, 40, 4]\n",
    "params = initialize_parameters(layer_dims)\n",
    "\n",
    "for l in range(1, len(layer_dims)):\n",
    "    print(\"Shape of W\" + str(l) + \":\", params['W' + str(l)].shape)\n",
    "    print(\"Shape of B\" + str(l) + \":\", params['b' + str(l)].shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, activation):\n",
    "   \n",
    "    forward_cache = {}\n",
    "    L = len(parameters) // 2                  \n",
    "    \n",
    "    forward_cache['A0'] = X\n",
    "\n",
    "    for l in range(1, L):\n",
    "        forward_cache['Z' + str(l)] = parameters['W' + str(l)].dot(forward_cache['A' + str(l-1)]) + parameters['b' + str(l)]\n",
    "        \n",
    "        if activation == 'tanh':\n",
    "            forward_cache['A' + str(l)] = tanh(forward_cache['Z' + str(l)])\n",
    "        else:\n",
    "            forward_cache['A' + str(l)] = relu(forward_cache['Z' + str(l)])\n",
    "            \n",
    "\n",
    "    forward_cache['Z' + str(L)] = parameters['W' + str(L)].dot(forward_cache['A' + str(L-1)]) + parameters['b' + str(L)]\n",
    "    \n",
    "    if forward_cache['Z' + str(L)].shape[0] == 1:\n",
    "        forward_cache['A' + str(L)] = sigmoid(forward_cache['Z' + str(L)])\n",
    "    else :\n",
    "        forward_cache['A' + str(L)] = softmax(forward_cache['Z' + str(L)])\n",
    "    \n",
    "    return forward_cache['A' + str(L)], forward_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    if Y.shape[0] == 1:\n",
    "        cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    else:\n",
    "        cost = -(1./m) * np.sum(Y * np.log(AL))\n",
    "        \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(AL, Y, parameters, forward_cache, activation):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(parameters)//2\n",
    "    m = AL.shape[1]\n",
    "    \n",
    "    grads[\"dZ\" + str(L)] = AL - Y  # After derivation of cross entropy loss and softmax activation function\n",
    "    grads[\"dW\" + str(L)] = 1./m * np.dot(grads[\"dZ\" + str(L)],forward_cache['A' + str(L-1)].T)\n",
    "    grads[\"db\" + str(L)] = 1./m * np.sum(grads[\"dZ\" + str(L)], axis = 1, keepdims = True)\n",
    "    \n",
    "    for l in reversed(range(1, L)):\n",
    "        if activation == 'tanh':\n",
    "            grads[\"dZ\" + str(l)] = np.dot(parameters['W' + str(l+1)].T,grads[\"dZ\" + str(l+1)])*derivative_tanh(forward_cache['A' + str(l)])\n",
    "        else:\n",
    "            grads[\"dZ\" + str(l)] = np.dot(parameters['W' + str(l+1)].T,grads[\"dZ\" + str(l+1)])*derivative_relu(forward_cache['A' + str(l)])\n",
    "            \n",
    "        grads[\"dW\" + str(l)] = 1./m * np.dot(grads[\"dZ\" + str(l)],forward_cache['A' + str(l-1)].T)\n",
    "        grads[\"db\" + str(l)] = 1./m * np.sum(grads[\"dZ\" + str(l)], axis = 1, keepdims = True)\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update parameters (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    L = len(parameters) // 2 \n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters, activation):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    y_pred, caches = forward_propagation(X, parameters, activation)\n",
    "    \n",
    "    if y.shape[0] == 1:\n",
    "        y_pred = np.array(y_pred > 0.5, dtype = 'float')\n",
    "    else:\n",
    "        y = np.argmax(y, 0)\n",
    "        y_pred = np.argmax(y_pred, 0)\n",
    "    \n",
    "    return np.round(np.sum((y_pred == y)/m), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Model for Our Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, learning_rate = 0.03, activation = 'relu', num_iterations = 3000):\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []              \n",
    "    \n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "    # print(\"parameters\", parameters)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, forward_cache = forward_propagation(X, parameters, activation)\n",
    "\n",
    "        cost = compute_cost(AL, Y)\n",
    "        costs.append(cost)\n",
    "\n",
    "        grads = backward_propagation(AL, Y, parameters, forward_cache, activation)\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "\n",
    "       \n",
    "    return parameters,grads,costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 1) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "X=[-1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1]\n",
    "y = [0,0,0,1]\n",
    "\n",
    "# make this suitable for input as NN\n",
    "X_train = np.array(X).reshape(-1, 1)\n",
    "Y_train = np.array(y).reshape(-1, 1)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "\n",
    "layers_dims = [14, 100, 40, 4]\n",
    "lr = 0.01\n",
    "iters = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get trained parameters , Gradients and cost then save it in CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters ,grads , costs= model(X_train, Y_train, layers_dims, learning_rate = lr, activation = 'relu', num_iterations = iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 1.08655214,  1.80982471,  1.01029217, ..., -0.71842277,\n",
       "         -0.59960604,  1.51287401],\n",
       "        [-1.98744071,  0.12322588,  0.30731344, ...,  0.11292759,\n",
       "         -0.08467472, -0.73554295],\n",
       "        [ 1.9036324 ,  1.99985731,  0.87112796, ...,  0.52140337,\n",
       "          1.50393093,  0.15683161],\n",
       "        ...,\n",
       "        [-0.30217358, -1.27342188,  0.11899082, ..., -0.47128811,\n",
       "          0.04086657, -1.30403125],\n",
       "        [ 0.74348986, -0.32424814, -0.90852946, ...,  0.13183239,\n",
       "         -0.84833121, -0.8020395 ],\n",
       "        [-1.28044534, -0.00368237,  0.46613842, ...,  0.64362311,\n",
       "          1.24858057, -0.20315255]]),\n",
       " 'b1': array([[-0.85362327],\n",
       "        [-0.72440469],\n",
       "        [ 0.26183882],\n",
       "        [ 0.49014536],\n",
       "        [-0.56905711],\n",
       "        [-0.84271878],\n",
       "        [-0.47026345],\n",
       "        [-0.41469008],\n",
       "        [-1.49534976],\n",
       "        [ 0.18982403],\n",
       "        [-1.68693888],\n",
       "        [-0.06435248],\n",
       "        [-0.77225488],\n",
       "        [ 0.20731127],\n",
       "        [-1.24754643],\n",
       "        [ 1.12351453],\n",
       "        [-0.45008948],\n",
       "        [-0.47357413],\n",
       "        [ 1.12370861],\n",
       "        [ 0.19743265],\n",
       "        [-1.34896767],\n",
       "        [ 1.08569407],\n",
       "        [-0.35729453],\n",
       "        [ 0.92113531],\n",
       "        [-0.69188058],\n",
       "        [ 1.53265119],\n",
       "        [ 0.34303427],\n",
       "        [ 0.95963526],\n",
       "        [ 1.02932525],\n",
       "        [-0.94950014],\n",
       "        [ 0.1331142 ],\n",
       "        [-1.51643181],\n",
       "        [-0.72428459],\n",
       "        [ 0.28541476],\n",
       "        [-0.94972152],\n",
       "        [-0.95897335],\n",
       "        [-0.33298394],\n",
       "        [-0.32000905],\n",
       "        [-1.85147667],\n",
       "        [-0.05076189],\n",
       "        [ 0.44565129],\n",
       "        [-0.20529117],\n",
       "        [-1.56800783],\n",
       "        [ 0.91908997],\n",
       "        [-0.9446997 ],\n",
       "        [-0.29178682],\n",
       "        [-0.2136347 ],\n",
       "        [ 2.55304027],\n",
       "        [ 0.02079896],\n",
       "        [ 0.28393382],\n",
       "        [-0.13819104],\n",
       "        [-0.4156754 ],\n",
       "        [ 0.94391555],\n",
       "        [-0.02108578],\n",
       "        [-0.12001079],\n",
       "        [-0.60478699],\n",
       "        [ 0.22358592],\n",
       "        [-0.80258137],\n",
       "        [ 1.24794078],\n",
       "        [-1.67054808],\n",
       "        [-0.19210015],\n",
       "        [-0.14906552],\n",
       "        [ 0.62017232],\n",
       "        [-1.25512564],\n",
       "        [-0.01144432],\n",
       "        [ 1.95955884],\n",
       "        [ 0.11464553],\n",
       "        [ 1.28822255],\n",
       "        [-0.49573648],\n",
       "        [ 1.73992801],\n",
       "        [-0.10420635],\n",
       "        [-0.41144595],\n",
       "        [-1.11919534],\n",
       "        [-0.93649304],\n",
       "        [-0.36695883],\n",
       "        [ 1.86879957],\n",
       "        [ 0.22811851],\n",
       "        [ 0.18469198],\n",
       "        [-0.59033483],\n",
       "        [ 0.04293538],\n",
       "        [-0.98452407],\n",
       "        [ 0.73484087],\n",
       "        [-0.52730167],\n",
       "        [ 0.95655644],\n",
       "        [-0.23575984],\n",
       "        [ 0.29145065],\n",
       "        [ 0.3349337 ],\n",
       "        [-0.42713431],\n",
       "        [ 0.39027852],\n",
       "        [-1.37159562],\n",
       "        [ 1.48420572],\n",
       "        [ 0.25826424],\n",
       "        [ 0.35087767],\n",
       "        [ 0.72685498],\n",
       "        [-1.1276015 ],\n",
       "        [-0.35077399],\n",
       "        [ 1.00521207],\n",
       "        [ 1.49475944],\n",
       "        [-0.26128277],\n",
       "        [ 0.14600518]]),\n",
       " 'W2': array([[ 0.96267551, -1.29171705, -1.40846133, ...,  0.9418779 ,\n",
       "          1.70751739, -1.20862377],\n",
       "        [ 0.28682899, -0.7172901 ,  0.83531719, ..., -0.22059557,\n",
       "         -2.47791624, -0.64102995],\n",
       "        [-0.45724908,  1.47429729, -0.08040974, ...,  1.22713161,\n",
       "         -2.13682866, -0.65445906],\n",
       "        ...,\n",
       "        [ 0.23498191,  1.60458672,  2.66390276, ...,  1.35361278,\n",
       "         -0.16005553,  0.08175315],\n",
       "        [ 2.63258171, -0.75618726,  1.11302173, ...,  0.32653931,\n",
       "         -0.31756988,  1.43898499],\n",
       "        [-0.9374581 , -1.12431431, -0.80996031, ..., -0.35769522,\n",
       "          0.11220858, -0.47893357]]),\n",
       " 'b2': array([[-0.37816018],\n",
       "        [-0.97328049],\n",
       "        [ 0.69211233],\n",
       "        [-1.05191255],\n",
       "        [-2.44347548],\n",
       "        [-0.21110581],\n",
       "        [-0.03062614],\n",
       "        [-0.02190083],\n",
       "        [-0.58555865],\n",
       "        [ 0.99776006],\n",
       "        [ 0.02719538],\n",
       "        [-0.12520714],\n",
       "        [-0.18917118],\n",
       "        [-0.49639022],\n",
       "        [ 0.35965806],\n",
       "        [ 0.45631829],\n",
       "        [ 0.53526855],\n",
       "        [-1.81790113],\n",
       "        [-1.43194771],\n",
       "        [ 0.37952688],\n",
       "        [-1.68525541],\n",
       "        [ 1.37609732],\n",
       "        [ 1.67272186],\n",
       "        [-0.17956571],\n",
       "        [ 0.36877769],\n",
       "        [-0.78758192],\n",
       "        [ 1.10525537],\n",
       "        [ 1.47821498],\n",
       "        [-2.000108  ],\n",
       "        [-0.14202455],\n",
       "        [ 0.17943063],\n",
       "        [-0.70644873],\n",
       "        [-0.35452816],\n",
       "        [ 0.33118683],\n",
       "        [ 0.74717838],\n",
       "        [ 0.17105487],\n",
       "        [-1.36855268],\n",
       "        [ 1.3707478 ],\n",
       "        [ 0.40350837],\n",
       "        [-0.04485269]]),\n",
       " 'W3': array([[-0.43780962,  0.14516531, -0.23563696,  0.93718433,  0.78248352,\n",
       "         -0.42150301,  1.09347916,  1.75454354,  1.6327064 , -1.42691767,\n",
       "         -0.21002895,  2.13250685,  0.65776563, -1.04621363, -0.86308807,\n",
       "          0.06735747, -0.78110164,  0.13413343, -0.39906794, -1.40547824,\n",
       "          0.0599214 , -0.951967  ,  1.82414937,  1.07114685,  1.95062888,\n",
       "         -0.1053805 , -1.08500695, -1.54479301,  0.60462445, -0.40583852,\n",
       "          0.06879006,  0.62270427, -1.57611597, -0.54230452, -1.13744247,\n",
       "          0.41736656,  0.02734488, -1.16756725, -0.23841313, -0.67154175],\n",
       "        [ 0.93676263,  0.29075372, -0.1959084 ,  0.04936696,  0.1992953 ,\n",
       "          0.5769276 ,  0.90720928,  0.14395161, -1.60380661,  0.02431266,\n",
       "         -0.62026155, -0.36374003, -0.93017989, -1.03278947, -0.18306114,\n",
       "         -0.63924068, -2.13673687, -0.37096056,  1.2450093 ,  0.23708101,\n",
       "          0.94575506,  2.01544881, -0.47186652, -1.11769927,  0.25960517,\n",
       "          0.11131086,  0.51660866,  0.77869767,  0.84403473,  0.86459237,\n",
       "         -2.01520467,  0.61730635, -0.63716382, -1.04033482,  1.45766187,\n",
       "         -3.00904846,  0.52135754, -1.37691391,  0.03875062, -0.98385596],\n",
       "        [-1.7823329 ,  1.59071612, -0.9972021 , -0.1254967 ,  0.29792774,\n",
       "         -1.6558435 , -1.30559385,  0.80133104,  0.62970859,  0.5670917 ,\n",
       "         -0.12348737,  1.59766948, -1.22147965,  0.41646329, -0.28739762,\n",
       "          0.96760517,  0.16441403, -1.81473768, -1.22127092, -0.2832281 ,\n",
       "         -1.3223089 , -0.32725784, -0.10328086,  0.9510293 ,  1.04619265,\n",
       "         -0.49681783, -1.34404504, -0.78469664,  0.93635237,  1.69687212,\n",
       "         -0.03038116, -1.49204803, -0.2168131 , -0.60405517,  1.30673051,\n",
       "         -0.53609508,  0.40816784, -3.36407328, -0.96753114, -1.36411655],\n",
       "        [ 1.5473212 ,  1.41582417, -1.25539911,  0.2181038 , -1.94079888,\n",
       "         -3.14346027,  0.30407712, -1.01613569, -0.01755948,  0.5569067 ,\n",
       "          0.86918163, -1.13560271, -0.66549981, -1.20149744,  0.46203047,\n",
       "         -0.97334385, -2.28503823,  0.48835278, -1.07161939, -0.28794256,\n",
       "          0.62169284, -1.74346113,  0.12423548, -0.81175739, -0.1618665 ,\n",
       "         -1.40460217, -0.62758672,  1.0764941 ,  0.88135201,  1.24148607,\n",
       "         -1.20781302,  0.30830261,  0.39873222,  0.30547976, -0.28865248,\n",
       "          1.19432724,  0.74486619,  1.17237127, -0.70488292,  1.24671173]]),\n",
       " 'b3': array([[-0.68218207],\n",
       "        [ 0.11402819],\n",
       "        [ 0.72378695],\n",
       "        [ 0.40190074]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads\n",
    "# make all grads np.float32 type\n",
    "# Convert all arrays to np.float32\n",
    "grads_dict = grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_dict['dW1'] = grads_dict['dW1'].T\n",
    "grads_dict['dW2'] = grads_dict['dW2'].T\n",
    "grads_dict['dW3'] = grads_dict['dW3'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 100), (100, 40), (40, 4))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_dict['dW1'].shape , grads_dict['dW2'].shape, grads_dict['dW3'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare lists to hold rows and keys\n",
    "rows = []\n",
    "\n",
    "# Iterate over the dictionary\n",
    "for key, value in grads_dict.items():\n",
    "    \n",
    "    if(key[1] == 'W'):\n",
    "        \n",
    "        for row in value:\n",
    "            \n",
    "            rows.append(row)  # Append the 1D array (row)\n",
    "        # Track which key this row belongs to\n",
    "\n",
    "rows.reverse()\n",
    "# Create DataFrame\n",
    "df_dws = pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = {\n",
    "    'db1': grads_dict['db1'].flatten(),\n",
    "    'db2': grads_dict['db2'].flatten(),\n",
    "    'db3': grads_dict['db3'].flatten()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dbs to DataFrame and save to CSV\n",
    "df_dbs = pd.DataFrame.from_dict(dbs, orient='index')\n",
    "df_dbs.to_csv('./answer/db.csv', header=False, index=False)\n",
    "\n",
    "\n",
    "df_dws.to_csv('./answer/dw.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
