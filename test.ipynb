{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z)) \n",
    "    return A\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    # Subtract the maximum value in z for numerical stability\n",
    "    shift_z = z - np.max(z, axis=0, keepdims=True)\n",
    "    exp_z = np.exp(shift_z)\n",
    "    return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    return A\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def derivative_relu(Z):\n",
    "    return np.array(Z > 0, dtype = 'float')\n",
    "\n",
    "def derivative_tanh(x):\n",
    "    return (1 - np.power(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #for avoiding vanishing gradiennt problem\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of W1: (100, 14)\n",
      "Shape of B1: (100, 1) \n",
      "\n",
      "Shape of W2: (40, 100)\n",
      "Shape of B2: (40, 1) \n",
      "\n",
      "Shape of W3: (4, 40)\n",
      "Shape of B3: (4, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layer_dims = [14, 100, 40, 4]\n",
    "params = initialize_parameters(layer_dims)\n",
    "\n",
    "for l in range(1, len(layer_dims)):\n",
    "    print(\"Shape of W\" + str(l) + \":\", params['W' + str(l)].shape)\n",
    "    print(\"Shape of B\" + str(l) + \":\", params['b' + str(l)].shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, activation):\n",
    "   \n",
    "    forward_cache = {}\n",
    "    L = len(parameters) // 2                  \n",
    "    \n",
    "    forward_cache['A0'] = X\n",
    "\n",
    "    for l in range(1, L):\n",
    "        forward_cache['Z' + str(l)] = parameters['W' + str(l)].dot(forward_cache['A' + str(l-1)]) + parameters['b' + str(l)]\n",
    "        \n",
    "        if activation == 'tanh':\n",
    "            forward_cache['A' + str(l)] = tanh(forward_cache['Z' + str(l)])\n",
    "        else:\n",
    "            forward_cache['A' + str(l)] = relu(forward_cache['Z' + str(l)])\n",
    "            \n",
    "\n",
    "    forward_cache['Z' + str(L)] = parameters['W' + str(L)].dot(forward_cache['A' + str(L-1)]) + parameters['b' + str(L)]\n",
    "    \n",
    "    if forward_cache['Z' + str(L)].shape[0] == 1:\n",
    "        forward_cache['A' + str(L)] = sigmoid(forward_cache['Z' + str(L)])\n",
    "    else :\n",
    "        forward_cache['A' + str(L)] = softmax(forward_cache['Z' + str(L)])\n",
    "    \n",
    "    return forward_cache['A' + str(L)], forward_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    if Y.shape[0] == 1:\n",
    "        cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    else:\n",
    "        cost = -(1./m) * np.sum(Y * np.log(AL))\n",
    "        \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(AL, Y, parameters, forward_cache, activation):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(parameters)//2\n",
    "    m = AL.shape[1]\n",
    "    \n",
    "    grads[\"dZ\" + str(L)] = AL - Y  # After derivation of cross entropy loss and softmax activation function\n",
    "    grads[\"dW\" + str(L)] = 1./m * np.dot(grads[\"dZ\" + str(L)],forward_cache['A' + str(L-1)].T)\n",
    "    grads[\"db\" + str(L)] = 1./m * np.sum(grads[\"dZ\" + str(L)], axis = 1, keepdims = True)\n",
    "    \n",
    "    for l in reversed(range(1, L)):\n",
    "        if activation == 'tanh':\n",
    "            grads[\"dZ\" + str(l)] = np.dot(parameters['W' + str(l+1)].T,grads[\"dZ\" + str(l+1)])*derivative_tanh(forward_cache['A' + str(l)])\n",
    "        else:\n",
    "            grads[\"dZ\" + str(l)] = np.dot(parameters['W' + str(l+1)].T,grads[\"dZ\" + str(l+1)])*derivative_relu(forward_cache['A' + str(l)])\n",
    "            \n",
    "        grads[\"dW\" + str(l)] = 1./m * np.dot(grads[\"dZ\" + str(l)],forward_cache['A' + str(l-1)].T)\n",
    "        grads[\"db\" + str(l)] = 1./m * np.sum(grads[\"dZ\" + str(l)], axis = 1, keepdims = True)\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    L = len(parameters) // 2 \n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters, activation):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    y_pred, caches = forward_propagation(X, parameters, activation)\n",
    "    \n",
    "    if y.shape[0] == 1:\n",
    "        y_pred = np.array(y_pred > 0.5, dtype = 'float')\n",
    "    else:\n",
    "        y = np.argmax(y, 0)\n",
    "        y_pred = np.argmax(y_pred, 0)\n",
    "    \n",
    "    return np.round(np.sum((y_pred == y)/m), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, learning_rate = 0.03, activation = 'relu', num_iterations = 3000):\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []              \n",
    "    \n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "    # print(\"parameters\", parameters)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, forward_cache = forward_propagation(X, parameters, activation)\n",
    "        print(\"dkjjkf\",AL)\n",
    "\n",
    "        cost = compute_cost(AL, Y)\n",
    "\n",
    "        grads = backward_propagation(AL, Y, parameters, forward_cache, activation)\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "\n",
    "       \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 1) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "X=[-1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1]\n",
    "y = [0,0,0,1]\n",
    "\n",
    "# make this suitable for input as NN\n",
    "X_train = np.array(X).reshape(-1, 1)\n",
    "Y_train = np.array(y).reshape(-1, 1)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "\n",
    "layers_dims = [14, 100, 40, 4]\n",
    "lr = 0.01\n",
    "iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dkjjkf [[0.26385234]\n",
      " [0.25950063]\n",
      " [0.05242399]\n",
      " [0.42422303]]\n",
      "dkjjkf [[0.21521787]\n",
      " [0.21539771]\n",
      " [0.04748174]\n",
      " [0.52190268]]\n",
      "dkjjkf [[0.17595881]\n",
      " [0.17831228]\n",
      " [0.0420422 ]\n",
      " [0.60368671]]\n",
      "dkjjkf [[0.14588069]\n",
      " [0.14994819]\n",
      " [0.03696157]\n",
      " [0.66720954]]\n",
      "dkjjkf [[0.12298827]\n",
      " [0.12733634]\n",
      " [0.03249737]\n",
      " [0.71717803]]\n",
      "dkjjkf [[0.10500874]\n",
      " [0.10933851]\n",
      " [0.02871268]\n",
      " [0.75694007]]\n",
      "dkjjkf [[0.09197021]\n",
      " [0.0957009 ]\n",
      " [0.02568248]\n",
      " [0.78664641]]\n",
      "dkjjkf [[0.0823465 ]\n",
      " [0.08532501]\n",
      " [0.02322841]\n",
      " [0.80910007]]\n",
      "dkjjkf [[0.07412564]\n",
      " [0.07676476]\n",
      " [0.02108528]\n",
      " [0.82802432]]\n",
      "dkjjkf [[0.06707533]\n",
      " [0.06962771]\n",
      " [0.01921892]\n",
      " [0.84407804]]\n",
      "dkjjkf [[0.06103591]\n",
      " [0.06348918]\n",
      " [0.01760237]\n",
      " [0.85787254]]\n",
      "dkjjkf [[0.0558281 ]\n",
      " [0.05817737]\n",
      " [0.01619498]\n",
      " [0.86979955]]\n",
      "dkjjkf [[0.05134806]\n",
      " [0.05357656]\n",
      " [0.01501633]\n",
      " [0.88005905]]\n",
      "dkjjkf [[0.04746595]\n",
      " [0.04955909]\n",
      " [0.0140125 ]\n",
      " [0.88896247]]\n",
      "dkjjkf [[0.04405626]\n",
      " [0.04601728]\n",
      " [0.0131226 ]\n",
      " [0.89680386]]\n",
      "dkjjkf [[0.0411221 ]\n",
      " [0.04304368]\n",
      " [0.01232243]\n",
      " [0.90351179]]\n",
      "dkjjkf [[0.03851998]\n",
      " [0.04040205]\n",
      " [0.01160656]\n",
      " [0.90947141]]\n",
      "dkjjkf [[0.0361802 ]\n",
      " [0.03801877]\n",
      " [0.01095799]\n",
      " [0.91484304]]\n",
      "dkjjkf [[0.03406831]\n",
      " [0.03586102]\n",
      " [0.01036849]\n",
      " [0.91970217]]\n",
      "dkjjkf [[0.03215526]\n",
      " [0.03390092]\n",
      " [0.00983103]\n",
      " [0.92411279]]\n",
      "dkjjkf [[0.03041878]\n",
      " [0.03211528]\n",
      " [0.00934102]\n",
      " [0.92812491]]\n",
      "dkjjkf [[0.02883316]\n",
      " [0.03048561]\n",
      " [0.00889059]\n",
      " [0.93179064]]\n",
      "dkjjkf [[0.02738263]\n",
      " [0.02898863]\n",
      " [0.00847607]\n",
      " [0.93515267]]\n",
      "dkjjkf [[0.02605207]\n",
      " [0.02761263]\n",
      " [0.00809395]\n",
      " [0.93824135]]\n",
      "dkjjkf [[0.02482822]\n",
      " [0.02634457]\n",
      " [0.00774082]\n",
      " [0.94108638]]\n",
      "dkjjkf [[0.02369962]\n",
      " [0.0251731 ]\n",
      " [0.00741374]\n",
      " [0.94371353]]\n",
      "dkjjkf [[0.02265631]\n",
      " [0.02408834]\n",
      " [0.00711011]\n",
      " [0.94614525]]\n",
      "dkjjkf [[0.02169046]\n",
      " [0.02308187]\n",
      " [0.00682819]\n",
      " [0.94839947]]\n",
      "dkjjkf [[0.02079321]\n",
      " [0.02214742]\n",
      " [0.00656528]\n",
      " [0.95049409]]\n",
      "dkjjkf [[0.01995792]\n",
      " [0.02128509]\n",
      " [0.00631883]\n",
      " [0.95243816]]\n",
      "dkjjkf [[0.01918024]\n",
      " [0.02048208]\n",
      " [0.00608822]\n",
      " [0.95424946]]\n",
      "dkjjkf [[0.01845355]\n",
      " [0.01973022]\n",
      " [0.00587206]\n",
      " [0.95594417]]\n",
      "dkjjkf [[0.0177733 ]\n",
      " [0.01902507]\n",
      " [0.00566909]\n",
      " [0.95753253]]\n",
      "dkjjkf [[0.01713545]\n",
      " [0.01836267]\n",
      " [0.00547823]\n",
      " [0.95902365]]\n",
      "dkjjkf [[0.01653757]\n",
      " [0.01773981]\n",
      " [0.00529923]\n",
      " [0.9604234 ]]\n",
      "dkjjkf [[0.01597367]\n",
      " [0.0171537 ]\n",
      " [0.00512949]\n",
      " [0.96174313]]\n",
      "dkjjkf [[0.01544277]\n",
      " [0.01659964]\n",
      " [0.00496934]\n",
      " [0.96298825]]\n",
      "dkjjkf [[0.01494194]\n",
      " [0.01607617]\n",
      " [0.00481789]\n",
      " [0.964164  ]]\n",
      "dkjjkf [[0.01446884]\n",
      " [0.01558099]\n",
      " [0.00467448]\n",
      " [0.96527569]]\n",
      "dkjjkf [[0.01402136]\n",
      " [0.01511197]\n",
      " [0.00453852]\n",
      " [0.96632815]]\n",
      "dkjjkf [[0.01359824]\n",
      " [0.0146674 ]\n",
      " [0.00440989]\n",
      " [0.96732447]]\n",
      "dkjjkf [[0.01319636]\n",
      " [0.01424598]\n",
      " [0.00428725]\n",
      " [0.96827041]]\n",
      "dkjjkf [[0.01281493]\n",
      " [0.01384466]\n",
      " [0.0041706 ]\n",
      " [0.96916981]]\n",
      "dkjjkf [[0.01245247]\n",
      " [0.01346286]\n",
      " [0.00405952]\n",
      " [0.97002515]]\n",
      "dkjjkf [[0.01210779]\n",
      " [0.0130993 ]\n",
      " [0.00395369]\n",
      " [0.97083922]]\n",
      "dkjjkf [[0.01177967]\n",
      " [0.01275275]\n",
      " [0.00385274]\n",
      " [0.97161484]]\n",
      "dkjjkf [[0.01146732]\n",
      " [0.01242221]\n",
      " [0.00375661]\n",
      " [0.97235387]]\n",
      "dkjjkf [[0.01116893]\n",
      " [0.01210702]\n",
      " [0.00366449]\n",
      " [0.97305955]]\n",
      "dkjjkf [[0.01088396]\n",
      " [0.01180515]\n",
      " [0.00357634]\n",
      " [0.97373456]]\n",
      "dkjjkf [[0.01061159]\n",
      " [0.01151636]\n",
      " [0.00349194]\n",
      " [0.97438011]]\n",
      "dkjjkf [[0.01035105]\n",
      " [0.01123987]\n",
      " [0.00341108]\n",
      " [0.97499801]]\n",
      "dkjjkf [[0.01010162]\n",
      " [0.01097494]\n",
      " [0.00333353]\n",
      " [0.9755899 ]]\n",
      "dkjjkf [[0.00986297]\n",
      " [0.010721  ]\n",
      " [0.00325933]\n",
      " [0.9761567 ]]\n",
      "dkjjkf [[0.00963384]\n",
      " [0.01047768]\n",
      " [0.00318788]\n",
      " [0.97670059]]\n",
      "dkjjkf [[0.00941397]\n",
      " [0.01024358]\n",
      " [0.00311921]\n",
      " [0.97722324]]\n",
      "dkjjkf [[0.00920285]\n",
      " [0.01001863]\n",
      " [0.00305317]\n",
      " [0.97772535]]\n",
      "dkjjkf [[0.009     ]\n",
      " [0.00980232]\n",
      " [0.00298962]\n",
      " [0.97820806]]\n",
      "dkjjkf [[0.00880496]\n",
      " [0.00959419]\n",
      " [0.00292844]\n",
      " [0.97867241]]\n",
      "dkjjkf [[0.0086176 ]\n",
      " [0.0093939 ]\n",
      " [0.00286968]\n",
      " [0.97911882]]\n",
      "dkjjkf [[0.00843692]\n",
      " [0.00920121]\n",
      " [0.00281283]\n",
      " [0.97954904]]\n",
      "dkjjkf [[0.0082629 ]\n",
      " [0.00901512]\n",
      " [0.00275802]\n",
      " [0.97996397]]\n",
      "dkjjkf [[0.00809516]\n",
      " [0.00883566]\n",
      " [0.00270511]\n",
      " [0.98036407]]\n",
      "dkjjkf [[0.0079334 ]\n",
      " [0.00866247]\n",
      " [0.00265403]\n",
      " [0.9807501 ]]\n",
      "dkjjkf [[0.00777732]\n",
      " [0.00849526]\n",
      " [0.00260468]\n",
      " [0.98112275]]\n",
      "dkjjkf [[0.00762691]\n",
      " [0.00833382]\n",
      " [0.00255715]\n",
      " [0.98148212]]\n",
      "dkjjkf [[0.00748127]\n",
      " [0.00817796]\n",
      " [0.00251097]\n",
      " [0.98182981]]\n",
      "dkjjkf [[0.00734059]\n",
      " [0.00802699]\n",
      " [0.00246632]\n",
      " [0.9821661 ]]\n",
      "dkjjkf [[0.00720457]\n",
      " [0.00788094]\n",
      " [0.00242311]\n",
      " [0.98249138]]\n",
      "dkjjkf [[0.00707299]\n",
      " [0.00773958]\n",
      " [0.00238126]\n",
      " [0.98280617]]\n",
      "dkjjkf [[0.00694564]\n",
      " [0.00760271]\n",
      " [0.00234071]\n",
      " [0.98311095]]\n",
      "dkjjkf [[0.00682263]\n",
      " [0.00747019]\n",
      " [0.00230159]\n",
      " [0.98340559]]\n",
      "dkjjkf [[0.00670306]\n",
      " [0.00734187]\n",
      " [0.00226339]\n",
      " [0.98369167]]\n",
      "dkjjkf [[0.00658731]\n",
      " [0.00721727]\n",
      " [0.00222641]\n",
      " [0.98396901]]\n",
      "dkjjkf [[0.00647508]\n",
      " [0.00709641]\n",
      " [0.00219053]\n",
      " [0.98423798]]\n",
      "dkjjkf [[0.00636624]\n",
      " [0.00697914]\n",
      " [0.00215568]\n",
      " [0.98449894]]\n",
      "dkjjkf [[0.0062607 ]\n",
      " [0.00686532]\n",
      " [0.00212188]\n",
      " [0.9847521 ]]\n",
      "dkjjkf [[0.00615827]\n",
      " [0.00675498]\n",
      " [0.00208906]\n",
      " [0.98499769]]\n",
      "dkjjkf [[0.00605873]\n",
      " [0.00664759]\n",
      " [0.00205709]\n",
      " [0.98523658]]\n",
      "dkjjkf [[0.00596204]\n",
      " [0.00654323]\n",
      " [0.00202602]\n",
      " [0.98546871]]\n",
      "dkjjkf [[0.00586809]\n",
      " [0.00644178]\n",
      " [0.00199579]\n",
      " [0.98569434]]\n",
      "dkjjkf [[0.00577676]\n",
      " [0.00634312]\n",
      " [0.00196639]\n",
      " [0.98591374]]\n",
      "dkjjkf [[0.00568804]\n",
      " [0.00624717]\n",
      " [0.00193783]\n",
      " [0.98612695]]\n",
      "dkjjkf [[0.00560168]\n",
      " [0.00615395]\n",
      " [0.00190998]\n",
      " [0.9863344 ]]\n",
      "dkjjkf [[0.00551762]\n",
      " [0.00606304]\n",
      " [0.00188284]\n",
      " [0.98653651]]\n",
      "dkjjkf [[0.0054358 ]\n",
      " [0.00597452]\n",
      " [0.00185639]\n",
      " [0.98673329]]\n",
      "dkjjkf [[0.00535614]\n",
      " [0.0058883 ]\n",
      " [0.00183063]\n",
      " [0.98692494]]\n",
      "dkjjkf [[0.00527855]\n",
      " [0.00580429]\n",
      " [0.00180551]\n",
      " [0.98711164]]\n",
      "dkjjkf [[0.00520309]\n",
      " [0.00572247]\n",
      " [0.00178111]\n",
      " [0.98729334]]\n",
      "dkjjkf [[0.0051294 ]\n",
      " [0.00564278]\n",
      " [0.0017572 ]\n",
      " [0.98747062]]\n",
      "dkjjkf [[0.00505759]\n",
      " [0.00556495]\n",
      " [0.0017339 ]\n",
      " [0.98764356]]\n",
      "dkjjkf [[0.00498757]\n",
      " [0.00548904]\n",
      " [0.00171116]\n",
      " [0.98781223]]\n",
      "dkjjkf [[0.00491928]\n",
      " [0.00541498]\n",
      " [0.00168896]\n",
      " [0.98797679]]\n",
      "dkjjkf [[0.00485266]\n",
      " [0.0053427 ]\n",
      " [0.00166729]\n",
      " [0.98813735]]\n",
      "dkjjkf [[0.00478772]\n",
      " [0.00527228]\n",
      " [0.00164618]\n",
      " [0.98829382]]\n",
      "dkjjkf [[0.00472426]\n",
      " [0.00520339]\n",
      " [0.0016255 ]\n",
      " [0.98844686]]\n",
      "dkjjkf [[0.00466229]\n",
      " [0.0051361 ]\n",
      " [0.00160529]\n",
      " [0.98859632]]\n",
      "dkjjkf [[0.00460178]\n",
      " [0.00507037]\n",
      " [0.00158555]\n",
      " [0.98874231]]\n",
      "dkjjkf [[0.00454266]\n",
      " [0.00500614]\n",
      " [0.00156624]\n",
      " [0.98888495]]\n",
      "dkjjkf [[0.00448495]\n",
      " [0.00494338]\n",
      " [0.0015474 ]\n",
      " [0.98902427]]\n",
      "dkjjkf [[0.00442854]\n",
      " [0.00488213]\n",
      " [0.00152896]\n",
      " [0.98916037]]\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, layers_dims, learning_rate = lr, activation = 'relu', num_iterations = iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.43567627, -0.16505049, -0.14271155, ..., -0.54904406,\n",
       "         -0.08772133, -0.10419455],\n",
       "        [ 0.30301263, -0.29395831, -0.04608338, ..., -0.18273396,\n",
       "         -0.03284379, -0.2500949 ],\n",
       "        [-0.0715961 ,  0.14174346, -0.18485411, ...,  0.19831964,\n",
       "         -0.05127021, -0.23722882],\n",
       "        ...,\n",
       "        [-0.16746788,  0.20635766,  0.12756443, ...,  0.35586704,\n",
       "          0.13919292,  0.01560054],\n",
       "        [ 0.19261142, -0.41303825,  0.43803091, ...,  0.10868329,\n",
       "         -0.16049154, -0.1733552 ],\n",
       "        [-0.19587037,  0.53237582, -0.15357787, ...,  0.19390227,\n",
       "          0.17632195, -0.05984731]]),\n",
       " 'b1': array([[-0.00155171],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.00741243],\n",
       "        [ 0.00619877],\n",
       "        [ 0.00579899],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.00776821],\n",
       "        [-0.0034506 ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.00144794],\n",
       "        [ 0.00041826],\n",
       "        [-0.00777097],\n",
       "        [-0.00749189],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.00699807],\n",
       "        [ 0.00583337],\n",
       "        [ 0.0004471 ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.00619309],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.0067577 ],\n",
       "        [ 0.0162421 ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.010366  ],\n",
       "        [-0.00421962],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.00027082],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.00249266],\n",
       "        [ 0.        ],\n",
       "        [-0.00232   ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.00232679],\n",
       "        [ 0.        ],\n",
       "        [ 0.00378667],\n",
       "        [ 0.00838046],\n",
       "        [ 0.        ],\n",
       "        [-0.00013164],\n",
       "        [ 0.        ],\n",
       "        [-0.0001829 ],\n",
       "        [-0.00074703],\n",
       "        [ 0.00208879],\n",
       "        [ 0.        ],\n",
       "        [-0.00027215],\n",
       "        [ 0.        ],\n",
       "        [ 0.00612102],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.0031178 ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.00422558],\n",
       "        [ 0.        ],\n",
       "        [ 0.00466003],\n",
       "        [ 0.00295637],\n",
       "        [ 0.00481448],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.00870897],\n",
       "        [ 0.00563315],\n",
       "        [-0.00871226],\n",
       "        [ 0.01347546],\n",
       "        [ 0.00675308],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.00253941],\n",
       "        [ 0.00060623],\n",
       "        [ 0.        ],\n",
       "        [ 0.00274688],\n",
       "        [ 0.        ],\n",
       "        [ 0.01055216],\n",
       "        [ 0.        ],\n",
       "        [ 0.00512773],\n",
       "        [ 0.        ],\n",
       "        [-0.00370505],\n",
       "        [ 0.01032229],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.00201961]]),\n",
       " 'W2': array([[ 0.01888281,  0.1223936 , -0.03009307, ..., -0.02098469,\n",
       "          0.18971607, -0.14781496],\n",
       "        [ 0.13012248, -0.03123921, -0.02712287, ..., -0.08030727,\n",
       "          0.13149408, -0.00182575],\n",
       "        [ 0.02910045,  0.10748997, -0.06978099, ...,  0.15496089,\n",
       "         -0.10700169,  0.06139516],\n",
       "        ...,\n",
       "        [ 0.27307485, -0.13746466,  0.17678781, ...,  0.09306274,\n",
       "          0.15430652,  0.13448223],\n",
       "        [-0.01669609, -0.16585829, -0.05543492, ..., -0.07824529,\n",
       "         -0.10150028,  0.10400471],\n",
       "        [-0.08518659,  0.17285818,  0.11712792, ..., -0.14089728,\n",
       "          0.00764415, -0.04124966]]),\n",
       " 'b2': array([[-8.78472382e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 2.60007148e-02],\n",
       "        [-8.08999772e-03],\n",
       "        [ 2.69841513e-03],\n",
       "        [-6.53657641e-04],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 1.63907946e-02],\n",
       "        [ 1.13730792e-02],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 2.32048615e-02],\n",
       "        [ 4.54781472e-03],\n",
       "        [-2.56947287e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [-9.03111149e-04],\n",
       "        [-4.30007046e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.06961081e-02],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 8.78002061e-03],\n",
       "        [ 4.61827039e-03],\n",
       "        [ 2.53941709e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 2.51679206e-02],\n",
       "        [ 1.65936339e-02],\n",
       "        [-4.30881893e-03],\n",
       "        [-1.87643025e-03],\n",
       "        [ 7.53211920e-05],\n",
       "        [-5.07899464e-03],\n",
       "        [ 0.00000000e+00],\n",
       "        [-3.33738744e-03],\n",
       "        [-2.86006311e-03],\n",
       "        [ 0.00000000e+00]]),\n",
       " 'W3': array([[ 0.07172481,  0.10530854,  0.0165877 , -0.29589489,  0.14267454,\n",
       "         -0.24660824, -0.05028403, -0.22495966, -0.05890969,  0.18948047,\n",
       "          0.11858323,  0.05347909, -0.04983289,  0.07454083, -0.27595326,\n",
       "         -0.23267496,  0.09199988, -0.0689409 ,  0.20273129, -0.21036663,\n",
       "          0.21201544,  0.04670421,  0.10569561,  0.0522989 ,  0.47635832,\n",
       "         -0.17370122, -0.15166646, -0.12947609,  0.24795987,  0.0766583 ,\n",
       "         -0.01364995, -0.30554973,  0.13733633,  0.15074801,  0.28759008,\n",
       "         -0.04741577, -0.12560272,  0.01019137, -0.04541085, -0.18510423],\n",
       "        [ 0.17311744,  0.31209115,  0.12389873, -0.08959378, -0.1242786 ,\n",
       "          0.04969681, -0.17529446,  0.10539844, -0.07089508, -0.153525  ,\n",
       "          0.05403882, -0.00524883, -0.06323923,  0.10771089, -0.09766808,\n",
       "         -0.18732119, -0.29307304,  0.44507556, -0.17055481,  0.06607763,\n",
       "          0.18299206, -0.2898179 , -0.08054455,  0.18258455, -0.04506535,\n",
       "          0.18384699, -0.05229236,  0.02904486,  0.20445726, -0.19662442,\n",
       "         -0.30799461,  0.12149336,  0.3282229 , -0.0320851 ,  0.01748031,\n",
       "         -0.09558721,  0.12454436,  0.09688681,  0.09330298, -0.19007113],\n",
       "        [-0.07366792,  0.04143512,  0.21992964, -0.16407305, -0.30776872,\n",
       "          0.11238934,  0.11133454, -0.04238178, -0.17822277, -0.46172675,\n",
       "         -0.00922425,  0.05004778, -0.10810457, -0.03360041, -0.18469949,\n",
       "         -0.07336365, -0.06060281, -0.14730688, -0.07674852, -0.13616199,\n",
       "          0.1379825 ,  0.07766195, -0.16165654, -0.21383359,  0.13881254,\n",
       "          0.1152345 , -0.06607754, -0.19437426, -0.23836662, -0.10905843,\n",
       "         -0.02154609, -0.08342943,  0.10115538, -0.08082474, -0.05787604,\n",
       "          0.34615984, -0.08931415,  0.04454904, -0.12742955,  0.16248215],\n",
       "        [-0.13411118,  0.00098729,  0.00715512,  0.3289996 , -0.15120906,\n",
       "         -0.02068315, -0.22351218,  0.20412121,  0.24857823,  0.21786891,\n",
       "         -0.18257021,  0.1981806 ,  0.05737766,  0.25187863,  0.034274  ,\n",
       "          0.24572159,  0.02339503,  0.06074449, -0.02813258, -0.11336986,\n",
       "          0.12951141,  0.13028297, -0.46471601, -0.37950209,  0.28422607,\n",
       "          0.2385867 ,  0.09856498,  0.03936041,  0.25101433, -0.01084832,\n",
       "          0.30759772,  0.258652  ,  0.1290336 , -0.08290741,  0.13403207,\n",
       "         -0.17605964,  0.11297484,  0.00995806, -0.18755634, -0.18482374]]),\n",
       " 'b3': array([[-0.02649992],\n",
       "        [-0.02761367],\n",
       "        [-0.00741336],\n",
       "        [ 0.06152695]])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
